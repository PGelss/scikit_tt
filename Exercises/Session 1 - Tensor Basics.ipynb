{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e4f44eb7",
   "metadata": {},
   "source": [
    "<h1 style=\"text-align: center;\"><b>TMQS Workshop 2024</b> @ Zuse Institute Berlin</h1>\n",
    "<h2 style=\"text-align: center;\">Summer School on Tensor Methods for Quantum Simulation</h2>\n",
    "<h2 style=\"text-align: center;\">June 3 - 5, 2024</h2>\n",
    "$\\def\\tcoreleft{\\textcolor{MidnightBlue}{\\Huge⦸}}$\n",
    "$\\def\\tcorecenter{\\textcolor{RedOrange}{\\Huge⦿}}$\n",
    "$\\def\\tcoreright{\\textcolor{MidnightBlue}{\\Huge\\oslash}}$\n",
    "<div style=\"text-align: center; background-color:#D6EAF8;padding-top:20px;padding-bottom:5px\">\n",
    "<table style=\"font-size:16pt\">\n",
    "    <tr style=\"background-color:#D6EAF8;\">\n",
    "        <td>$\\tcoreleft$</td>\n",
    "        <td>$-$</td>\n",
    "        <td>$\\tcoreleft$</td>\n",
    "        <td>$-$</td>\n",
    "        <td>$\\tcoreleft$</td>\n",
    "        <td>$-$</td>\n",
    "        <td>$\\cdots$</td>\n",
    "        <td>$-$</td>\n",
    "        <td>$\\tcorecenter$</td>\n",
    "        <td>$-$</td>\n",
    "        <td>$\\cdots$</td>\n",
    "        <td>$-$</td>\n",
    "        <td>$\\tcoreright$</td>\n",
    "        <td>$-$</td>\n",
    "        <td>$\\tcoreright$</td>\n",
    "    </tr>\n",
    "    <tr style=\"background-color:#D6EAF8;\">\n",
    "        <td style=\"text-align: center;\">$\\tiny\\mid$</td>\n",
    "        <td></td>\n",
    "        <td style=\"text-align: center;\">$\\tiny\\mid$</td>\n",
    "        <td></td>\n",
    "        <td style=\"text-align: center;\">$\\tiny\\mid$</td>\n",
    "        <td></td>\n",
    "        <td></td>\n",
    "        <td></td>\n",
    "        <td style=\"text-align: center;\">$\\tiny\\mid$</td>\n",
    "        <td></td>\n",
    "        <td></td>\n",
    "        <td></td>\n",
    "        <td style=\"text-align: center;\">$\\tiny\\mid$</td>\n",
    "        <td></td>\n",
    "        <td style=\"text-align: center;\">$\\tiny\\mid$</td>\n",
    "    </tr>\n",
    "</table>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58a30939-f570-45cd-a736-d6f21aeb2a0c",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c3441f3-b5a9-42c4-ba21-2bc682b0d8ac",
   "metadata": {},
   "source": [
    "## **Session 1 - Tensor Basics**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f6cc702",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c8096861-c33f-49b8-9bda-62529ce31bc3",
   "metadata": {},
   "source": [
    "## Exercise 1.1\n",
    "\n",
    "... a bit of theory to begin with.\n",
    "\n",
    "The following exercises are intended to demonstrate to you that one can handle tensors in a very natural way, much like with classical vectors and matrices. In the end, standard linear algebra provides the foundational understanding necessary to grasp the concepts of tensors effectively. By extending basic concepts, tensors offer a powerful framework for describing and manipulating multidimensional data in various fields such as physics, engineering, and machine learning.\n",
    "\n",
    "Suppose $T$ and $U$ are tensors in $\\mathbb{C}^{N}$, where $N = (n_1, \\dots , n_d)$ and $d \\in \\mathbb{N}$. Furthermore, let $G, H \\in \\mathbb{C}^{N \\times N}$. Show that\n",
    "\n",
    "**a)**$\\quad T^\\dagger \\cdot U = \\langle \\text{vec}(T), \\text{vec}(U) \\rangle$\n",
    "\n",
    "**b)**$\\quad \\lVert T \\rVert_F = \\lVert \\text{vec}(T) \\rVert_2$\n",
    "\n",
    "**c)**$\\quad \\text{tr}(G^\\dagger \\cdot H) = \\langle \\text{vec}(G), \\text{vec}(H) \\rangle$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57638421-d883-4f7f-ab0f-aae0505cffca",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "41a28d39-ecbe-4a8b-9ed0-161d36c14c73",
   "metadata": {},
   "source": [
    "## Exercise 1.2 \n",
    "\n",
    "... now onto the basic implementation\n",
    "\n",
    "We turn to the practical implementation of tensors and their limitations. Tensors in full format can be easily created and multiplied/contracted in Python using the standard package NumPy:\n",
    "\n",
    "> import numpy as np\n",
    "\n",
    "In addition, we also need the Matplotlib and time package for this task:\n",
    "\n",
    "> import matplotlib.pyplot as plt\n",
    "> \n",
    "> import time\n",
    "\n",
    "Create random order-$d$ tensors in $\\mathbb{R}^{N \\times N}$ with $N=(2,\\dots,2)$ for different dimensions $d = 1, 2, \\dots, 10$:\n",
    "\n",
    "> T = np.random.random_sample(2*d*[2])\n",
    "\n",
    "Compute the storage (```T.size * T.itemsize```) of every instance and plot the results:\n",
    "\n",
    "> plt.plot(np.arange(1,11), storage)\n",
    "\n",
    "Rerun the expriment and reshape every instance into an array in $\\mathbb{R}^{2^d \\times 2^d}$ and compute an SVD:\n",
    "\n",
    "> T_mat = T.reshape([2** d, 2**d])\n",
    ">\n",
    "> U, S, Vt = np.linalg.svd(T)\n",
    "\n",
    "Measure the CPU time using:\n",
    "\n",
    "> start_time = time.time()\n",
    ">\n",
    "> ...\n",
    ">\n",
    "> end_time = time.time() - start_time\n",
    "\n",
    "Plot the results and interpret both plots in terms of storage consumption and computational complexity, respectively. Given a matrix $M \\in \\mathbb{R}^{m \\times n}$, $m \\geq n$, the overall cost for computing an SVD is $O(m n^2)$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e827c10b-ffbd-4687-8647-ba488b100e61",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "75fa57e8-6077-4b07-ad00-06251ba6a395",
   "metadata": {},
   "source": [
    "## Exercise 1.3 \n",
    "\n",
    "Lastly, we will create a special form of tensor, sometimes called the delta tensor. We define $\\Delta \\in \\mathbb{R}^{n \\times n \\times n}$ as\n",
    "\n",
    "$\\hspace{1cm}$$\\Delta_{i,j,k} = \\begin{cases} 1 & \\text{if}~i=j=k\\\\ 0& \\text{otherwise.}\\end{cases}$\n",
    "\n",
    "Now, we want to try various contractions with this tensor. To do this, let's choose $n=3$ and additionally define the vectors $v=(1,2,3)$ and $w=(4,5,6)$.\n",
    "\n",
    "Use NumPy's einsum function to compute the following contractions:\n",
    "\n",
    "\\begin{array}{}\n",
    "  &   &   &   &   &                    &         & v &           &                    &   &         &   &           &   \\\\\n",
    "  &   &   &   &   &                    &         & | &           &                    &   &         & | &           &   \\\\\n",
    "- & D & = & D & - & \\qquad\\qquad\\qquad &         & D &           & \\qquad\\qquad\\qquad &   &         & D &           &   \\\\\n",
    "  &   &   &   &   &                    & \\diagup &   & \\diagdown &                    &   & \\diagup &   & \\diagdown &   \\\\\n",
    "  &   &   &   &   &                    &         &   &           &                    & v &         &   &           & w\n",
    "\\end{array}\n",
    "\n",
    "Examine the results and try to explain how they arise.\n",
    "\n",
    "*Hint:* In order to contract two or more tensors with NumPy's einsum function, assign a variable (```i, j, k, ...```) to each mode of the tensors. Modes that are to be contracted receive the same variables. Example: ```np.einsum('ijk, jl -> ikl', T_1, T_2)``` contracts an order-3 tensor $T_1$ and a matrix $T_2$ on a common mode (second of $T_1$, first of $T_2$). The result is again an order-3 tensor."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
